# @package _global_.model.fusion
type: physics_informed   # alias to cross_attend
attn:
  layers: 2
  heads: 4
  qkv_bias: true
  dropout: 0.05
  resid_dropout: 0.05
  norm: layernorm
symbolic_injection:
  include_molecule_masks: true
  include_detector_seams: true
  include_wavelengths: true
  include_snr_weights: true
attention_bias_init: 0.25
export:
  attn_weights: true
  taps: true
