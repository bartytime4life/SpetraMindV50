# configs/model/mu_decoder/base.yaml
# Multi-Scale μ Decoder — SpectraMind V50
# Predicts mean transit depth (μ) across 283 bins from fused latent representation.
# See ARCHITECTURE.md §5.3 for design rationale.
model:
  decoders:
    mu_decoder:
      enabled: true
      type: "multi_scale"      # [multi_scale, simple_mlp]
      in_dim: 256              # Matches fusion output dimension
      hidden_dims: [512, 256]  # Progression of hidden layers
      scales:                  # Multi-scale prediction heads
        - name: "coarse"
          bins: 71             # e.g., 4× downsample
          loss_weight: 0.25
        - name: "mid"
          bins: 142            # 2× downsample
          loss_weight: 0.25
        - name: "fine"
          bins: 283            # Full resolution
          loss_weight: 0.50
      activation: "gelu"       # Non-linear activation
      dropout: 0.1             # Regularization
      skip_fusion: true        # Enable coarse→mid→fine skip connections
      norm: "layernorm"        # [batchnorm, layernorm, rmsnorm]
      output_activation: null  # No activation — raw μ for GLL + symbolic losses
      init: "xavier_uniform"   # Weight initialization
      export_attention: false  # Set true if decoder uses attention for explainability
      aux_losses: true         # Apply loss at coarse/mid scales (λ from scales list)